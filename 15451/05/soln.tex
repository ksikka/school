\documentclass[11pt]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{fancyhdr}

\oddsidemargin0cm
\topmargin-2cm
\textwidth16.5cm
\textheight23.5cm

\newcommand{\question}[2] {\vspace{.25in} \hrule\vspace{0.5em}
\noindent{\bf #1: #2} \vspace{0.5em}
\hrule \vspace{.10in}}
\renewcommand{\part}[1] {\vspace{.10in} {\bf (#1)}}

\newcommand{\myname}{Karan Sikka}
\newcommand{\myandrew}{ksikka@cmu.edu}
\newcommand{\myhwnum}{05}

\setlength{\parindent}{0pt}
\setlength{\parskip}{5pt plus 1pt}
 
\pagestyle{fancyplain}
\lhead{\fancyplain{}{\textbf{HW\myhwnum}}}
\rhead{\fancyplain{}{\myname\\ \myandrew}}
\chead{\fancyplain{}{15-451}}

\begin{document}

\medskip

\thispagestyle{plain}
\begin{center}
{\Large 15-451 Assignment \myhwnum} \\
\myname \\
\myandrew \\
Collaborated with Dave Cummings and Sandeep Rao.\\
Recitation: A \\
\today \\
\end{center}

\question{1}{Cell Towers}
Profit = Actual Revenue - Cost\\
Profit = Total Possible Revenue - Lost Revenue - Cost\\
LR + Cost = TPR - Profit

Since the total possible revenue is some constant, minimizing the LHS of the above equation maximizes the profit.\\
So finding the min (lost revenue + cost) is the right thing to do. Now lets see how to do it.

In part (a) we will construct a graph.\\
In part (b) we will show that the finding the min cut correctly finds the cell towers to build which min (lost revenue + cost)\\
In part (c) we will give an algorithm to find the min cut.\\
In part (c) we will show that it's efficient.

\part{a}
Construct a bipartite graph (nodes are partitioned into A and B with no edges within A or B) as follows:

There is a node in A for every revenue-generating pair of cell towers.\\
Add a source node.\\
Create edges from the source node to every node in A with capacity of the revenue generated by the pair of cell towers represented by the node in A.

For each node in A, for each cell tower in the pair represented by that node, connect that node to the cell tower in B.\\
Give that edge an infinite capacity.
\\
There is a node in B for every cell tower.\\
Add a target node.\\
Create edges from every node in B to the target with capacity of the cost of building the tower represented by the node in B.

\part{b}
Notice that the min cut will never contain an edge going from A to B, because those edges have infinite capacity.\\
Therefore the node representing a pair of cell towers in A will be in the same vertex set as the individual cell towers in B after the cut is performed.

If the min cut contains an edge from B to target, we say that we built that cell tower of the node in B, and incurred a financial cost of the amount of that capacity.\\
If the min cut contains an edge from source to A, we say that at least one of the cell towers in pair of the node in A will not be built, and we lost revenue of the amount of that capacity.

Min-cut will minimize the cost + the lost revenue

The edges of the min cut from B to target will tell you which cell towers to build.

\part{c}
You can perform Edmund-Karp \#1 until your last residual graph when the algorithm terminates. On the residual graph, find all vertices reachable from the source. This is one set in the min cut, the other set has the nodes not in the first set.\\
This is correct because the algorithm pushes max flow until some edges have residual capacity 0 and they disappear, disconnecting the graph. This max flow value is exactly equal to the min cut value. Therefore the vertices not reachable must have \\
been separated by the edges of the min cut.

Find the edges between the sets, look for edges where one node is the target, and the other node in the edge is a cell tower you should build.

\part{d}

The number of nodes and edges in the graph is no more than polynomial in the number of cell towers and revenue pairs due to the way we constructed the graph.\\
The Edmund-Karp algorithm is polynomial in nodes and edges.\\
Therefore this algorithm runs in polynomial time and is ``efficient''.

\question{2}{Eliminating Negative Edges}
\part{a}
Original graph had no negative cycles. We introduce a node s, create an edge from s to every other node, and give edge weight 0.\\
A new negative cycle would have to include s. However that can't be because there are no edges going into s. Therefore there are no negative cycles in the new graph.

\part{b}

Case the shortest path to $v$ goes through $u$. \\
$\Phi(v) = \mathtt{shortest\_path\_from\_u\_to\_v} + \Phi(u)$\\
and we know that $\mathtt{shortest\_path\_from\_u\_to\_v} \leq \mathtt{len}(u,v)$\\
$\implies \Phi(v) \leq len(u,v) + \Phi(u) \implies \Phi(v) - \Phi(u) \leq len(u,v)$.

Case the shortest path to $v$ does not go through $u$. \\
Then the shortest path from $s$ to $v$ is even shorter than the shortest path that goes through $u$,\\
so $\Phi(v)$ is smaller than was shown in the previous case, so the original claim holds.


\part{c}
Consider a path of nodes $v_1, v_2, ..., v_k$. When you sum the new edge lengths, you see all of the $\Phi$ terms cancel out except\\
you are left with $\Phi(v_1) - \Phi(v_k)$. So the length of a path in the new graph is $\mathtt{old\_path\_len + \Phi(v_1) - \Phi(v_k)}$

For each node, run djikstra's single source shortest path algorithm.\\
We claim that the resulting shortest paths will be the true shortest paths in the original graph.\\
This is because the shortest path from some $u$ to some $v$ is going to be the path among all paths from $u$ to $v$ minimizing $\mathtt{old\_path\_len(u,v) + \Phi(u) - \Phi(v)}$ where $\Phi(u) - \Phi(v)$ is a constant quantity for a given $u,v$.\\
The real length of the path from $u$ to $v$ is $\mathtt{new\_path\_len(u,v) - \Phi(u) + \Phi(v)}$\\
The cost of running djikstra's $n$ times using the fibonacci heaps version is $O(nm + n^2lg(n)$


\question{3}{Color Me Red, Color Me Blue}

\newcommand{\rright}[0]{\texttt{r-{\textgreater}right }}
\newcommand{\rleft}[0]{\texttt{r-{\textless}left }}

\newcommand{\mrleft}[0]{\texttt{r->left }}
\newcommand{\mrright}[0]{\texttt{r->right }}

For convenience, we will call a $(k,n-k)$ partition which minimizes split edges a ``minimizing k-partition''.

We will consider a function kPart as follows:\\

Given a node $n$, value $i (1 \leq i \leq k)$ and bit $b$,\\
The function returns NONE, or SOME $(A,B,S)$.\\

$\mathtt{kPart}(n,k,b) = \mathtt{NONE}$ signifies that no k-partition of vertices in the subtree rooted at $n$ exists, which happens when $(k > |n|)$. \\
$\mathtt{kPart}(n,k,b) = \mathtt{SOME}(A,B,S)$ signifies that $A,B$ is some minimizing k-partition the nodes of the subtree rooted at $n$ such that $n \in A \iff b = 1$, $S$ is the set of split edges\\


We create a memo table for the computation which we assume is available to the function.\\
The table can be accessed by $T[n][k][b]$ where $n$ is a node, $k$ is an int from 0 to $k$, $b$ is a bit.\\
We initialize the table with NULLs, and compute the values in the following recursive function.\\
Note that the table has $n*(k+1)*2$ cells.

The procedure to compute kPart(r,k,b) is as follows:\\
    (Check if value has already been computed. )\\
    If $T[r][k][i] \neq \text{NULL}$,\\
       return $T[r][k][i]$\\
    ( If k=0, A is empty, B is rest of nodes. )\\
    If $k = 0$,\\
       $T[r][k][i] = (\{\}, {\mathtt{all\_nodes}(b)}, \{\})$\\
    ( If k > n, no set A can be formed... )\\
    If $k > n$,\\
       $T[r][k][i] = \mathtt{DNE}$

    If both \rleft and \rright are NULL,
        If $k=1$
            $T[r][k][i] = (\{r\}, \{\}, \{\})$
        Else
            % k > n and this case would have been caught earlier
    If only \rleft is NULL,
        ( There are four cases. )\\
        ( We will compute the number of split edges in each case, )\\
        ( take the case with minimum split edges )\\
        ( return the partitioning for that case. )\\
        $T[r][k][i]$ = The $(A,B,S)$ with the minimum $|S|$ over the following answers computed for all possible colorings of r and \rright that might yield a minimizing k-partition:\\
          $r \in A, \mrright \in A \implies $\\
            $A_r, B_r, S_r = \mathtt{kPart}(\mrright,k-1,1)$\\
            answer is $(\{r\} \cup A_r, B_r, S_r)$\\
          $r \in A, \mrright \in B \implies $\\
            $A_r, B_r, S_r = \mathtt{kPark}(\mrright,k-1,0)$\\
            answer is $(\{r\} \cup A_r, B_r, S_r \cup \{(r, \mrright)\})$\\
          $r \in B, \mrright \in A \implies $\\
            $A_r, B_r, S_r = \mathtt{kPark}(\mrright,k,1)$\\
            answer is $(A_r,\{r\} \cup B_r, S_r \cup \{(r, \mrright)\})$\\
          $r \in B, \mrright \in B \implies $ 1 + $T[\mrright][k][0]$\\
            $A_r, B_r, S_r = \mathtt{kPark}(\mrright,k,0)$\\
            answer is $(A_r,\{r\} \cup B_r, S_r)$

    If only \rright is NULL,\\
        Logic is symmetric to above case.

    If \rleft and \rright are not NULL,\\
        $T[r][k][i]$ = The $(A,B,S)$ with the minimum $|S|$ over the following answers computed for all possible colorings of r, \rright, and \rleft that might yield a minimizing k-partition:\\
                Left and right subtrees can be partitioned in at most k+1 ways such that the sum of their A sets should be $k-1$ if $r$ in $A$ or $k$ otherwise.\\
                We must minimize the number of split edges accross all variations of A-set-size.

          $r \in A, \mrleft \in A, \mrright \in A\\
              \texttt{minimize} |S| \texttt{over\_all\_integral} i,j \geq 0 st i+j = k-1$\\
                $A_l, B_l, S_l = \mathtt{kPart}(\mrleft,i,1)$\\
                $A_r, B_r, S_r = \mathtt{kPart}(\mrright,j,1)$\\
                $\texttt{over\_all\_integral} (A_l \cup A_r \cup \{r\},B_l \cup B_r,S_l \cup S_r)$

          $r \in A, \mrleft \in A, \mrright \in B\\
              \texttt{minimize} |S| \texttt{over\_all\_integral} i,j \geq 0 st i+j = k-1\\
                    \mathtt{kPart}(\mrleft,i,1) + 1 + \mathtt{kPart}(\mrright,j,0)$\\
                $\texttt{over\_all\_integral} (A_l \cup A_r \cup \{r\},B_l \cup B_r,S_l \cup S_r \cup \{(r, \mrright)\})$

          $r \in A, \mrleft \in B, \mrright \in A\\
              \texttt{minimize} |S| \texttt{over\_all\_integral} i,j \geq 0 st i+j = k-1\\
                1 + \mathtt{kPart}(\mrleft,i,0) +     \mathtt{kPart}(\mrright,j,1)$\\
                $\texttt{over\_all\_integral} (A_l \cup A_r \cup \{r\},B_l \cup B_r,S_l \cup S_r \cup \{(r, \mrleft)\})$

          $r \in A, \mrleft \in B, \mrright \in B\\
              \texttt{minimize} |S| \texttt{over\_all\_integral} i,j \geq 0 st i+j = k-1\\
                1 + \mathtt{kPart}(\mrleft,i,0) + 1 + \mathtt{kPart}(\mrright,j,0)$\\
                $\texttt{over\_all\_integral} (A_l \cup A_r \cup \{r\},B_l \cup B_r,S_l \cup S_r \cup \{(r, \mrleft),(r, \mrright)\})$

          $r \in B, \mrleft \in A, \mrright \in A\\
              \texttt{minimize} |S| \texttt{over\_all\_integral} i,j \geq 0 st i+j = k\\
                1 + \mathtt{kPart}(\mrleft,i,1) + 1 + \mathtt{kPart}(\mrright,j,1)$\\
                $\texttt{over\_all\_integral} (A_l \cup A_r,B_l \cup B_r \cup \{r\},S_l \cup S_r \cup \{(r, \mrleft),(r, \mrright)\})$

          $r \in B, \mrleft \in A, \mrright \in B\\
              \texttt{minimize} |S| \texttt{over\_all\_integral} i,j \geq 0 st i+j = k\\
                1 + \mathtt{kPart}(\mrleft,i,1) +     \mathtt{kPart}(\mrright,j,0)$\\
                $\texttt{over\_all\_integral} (A_l \cup A_r,B_l \cup B_r \cup \{r\},S_l \cup S_r \cup \{(r, \mrleft)\})$

          $r \in B, \mrleft \in B, \mrright \in A\\
              \texttt{minimize} |S| \texttt{over\_all\_integral} i,j \geq 0 st i+j = k\\
                    \mathtt{kPart}(\mrleft,i,0) + 1 + \mathtt{kPart}(\mrright,j,1)$\\
                $\texttt{over\_all\_integral} (A_l \cup A_r,B_l \cup B_r \cup \{r\},S_l \cup S_r \cup \{(r, \mrright)\})$

          $r \in B, \mrleft \in B, \mrright \in B\\
              \texttt{minimize} |S| \texttt{over\_all\_integral} i,j \geq 0 st i+j = k\\
                    \mathtt{kPart}(\mrleft,i,0) +     \mathtt{kPart}(\mrright,j,0)$\\
                $\texttt{over\_all\_integral} (A_l \cup A_r,B_l \cup B_r \cup \{r\},S_l \cup S_r)$


   return $T[r][k][i]$


Each function call costs $O(1)$ if the value in the table is computed, else it makes recursive calls, but these are also $O(1)$ if computed already.
The base case takes $O(1) to compute$. We see that each function call we makes at most $8(k+1)$ recursive function calls, we do this a total of $n$ times. That's at most O(nk) function calls total accross the entire algorithm.

\end{document}





